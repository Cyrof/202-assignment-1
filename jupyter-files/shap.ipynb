{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# SHapley Additive exPlanations (SHAP)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Library Imports "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import pickle\n", "\n", "import pandas as pd\n", "import numpy as np\n", "import shap\n", "from matplotlib import pyplot as plt"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["RAND_STATE = 0"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Importing the Train and Test Sets"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["dataset_folder = f\"{os.path.abspath(os.path.join(os.getcwd(), os.pardir))}/datasets\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train = pd.read_csv(os.path.join(dataset_folder, \"obesity_X_train.csv\"), index_col=0)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_test = pd.read_csv(os.path.join(dataset_folder, \"obesity_X_test.csv\"), index_col=0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As with the rest of the stages, we make a variant of the sets without the height and weight columns for comparison:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train_no_hw = X_train.drop([\"Height\", \"Weight\"], axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_test_no_hw = X_test.drop([\"Height\", \"Weight\"], axis=1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For processing the SHAP values for one-hot encoded features, we will also need the unencoded sets:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_train_unencoded = pd.read_csv(os.path.join(dataset_folder, \"obesity_X_train_unencoded.csv\"), index_col=0)\n", "X_train_unencoded"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_test_unencoded = pd.read_csv(os.path.join(dataset_folder, \"obesity_X_test_unencoded.csv\"), index_col=0)\n", "X_test_unencoded"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Importing the Random Forest Classifiers\n", "We import the random forest classifiers that we trained previously. SHAP values will be calculated for these models to explain their predictions."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def import_model(filename):\n", "    file_path = f\"{os.path.abspath(os.path.join(os.getcwd(), os.pardir))}/models/{filename}\"\n", "    with open(file_path, 'rb') as file: \n", "        model = pickle.load(file)\n", "    print(f\"Model imported from {file_path}\")\n", "    return model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rand_forest = import_model(\"rand_forest.pkl\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["rand_forest_no_hw = import_model(\"rand_forest_no_hw.pkl\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Importing Encoders\n", "We import the label encoder for the target feature so that we can encode the original values for indexing purposes."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def import_encoder(filename):\n", "    file_path = f\"{os.path.abspath(os.path.join(os.getcwd(), os.pardir))}/encoders/{filename}\"\n", "    with open(file_path, 'rb') as file: \n", "        encoder = pickle.load(file)\n", "    print(f\"Encoder imported from {file_path}\")\n", "    return encoder"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["target_le = import_encoder(\"target_le.pkl\")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["target_class_label_d = {cls: idx for idx, cls in enumerate(target_le.classes_)}\n", "target_class_label_d"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We also import the one-hot encoder, which is needed when summing the SHAP values for one-hot encoded features:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nominal_ohe = import_encoder(\"nominal_ohe.pkl\")"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Explanations"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Calculating the SHAP Values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["First, we create the explainers and calculate the SHAP values:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["explainer = shap.TreeExplainer(rand_forest)\n", "shap_values = explainer(X_test)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["explainer_no_hw = shap.TreeExplainer(rand_forest_no_hw)\n", "shap_values_no_hw = explainer_no_hw(X_test_no_hw)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Undoing the One-Hot Encoding\n", "However, because our nominal features are one-hot encoded, their SHAP values have been \"separated\". We need to group these one-hot encoded features back together. For reference, here is a list of all columns:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["X_test.columns"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Summing Shape Values\n", "We first need to calculate the SHAP values for each nominal feature, which is done by taking the sum of the SHAP values for each feature's corresponding set of one-hot encoded features. We begin by determining the number of output one-hot encoded features for each nominal feature:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["n_ohe_feats: dict[str, int] = {\n", "    feat_name: (len(categories) if drop_idx is None else len(categories) - 1)\n", "    for feat_name, categories, drop_idx\n", "    in zip(nominal_ohe.feature_names_in_, nominal_ohe.categories_, nominal_ohe.drop_idx_)\n", "}\n", "n_ohe_feats"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Our one-hot encoded dataset has the one-hot encoded features after all numerical features.\n", "Hence, the number of numerical features will tell us the start index of the first one-hot encoded feature:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["numerical_feature_count = 8\n", "numerical_feature_count_no_hw = 6"]}, {"cell_type": "markdown", "metadata": {}, "source": ["To calculate the sum, we first group the SHAP value columns by their original nominal features.\n", "Then, we sum the SHAP values for each group column-wise."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Split the SHAP values for the one-hot encoded features.\n", "# Each entry in split contains the SHAP values for the multiple one-hot encoded features of the original categorical feature.\n", "values_split = np.split(shap_values.values[:, numerical_feature_count:, :], np.cumsum(list(n_ohe_feats.values())[:-1]), axis=1)\n", "\n", "# Sum the SHAP values for each group.\n", "values_summed = np.array([vals.sum(axis=1) for vals in values_split])\n", "\n", "# We need to swap the first two axes since the first axis should index the instances and the second axis should index the features.\n", "unohe_values = np.swapaxes(values_summed, 0, 1)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["As a sanity check, we check the shape. The first axis's value should be the same as the number of instances, the second axis's value should be the number of nominal features and the third axis's value should be `2` since we only have two different categories for the target feature."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["unohe_values.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Finally, we concatenate back the numerical features and double check the shape again:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["new_values = np.concatenate((shap_values.values[:, :numerical_feature_count, :], unohe_values), axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# 2nd axis should be 16, the number of original input features.\n", "new_values.shape"]}, {"cell_type": "markdown", "metadata": {}, "source": ["At last, we can replace the old SHAP values:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shap_values.values = new_values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Fixing the Data Values"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Unfortunately, we are not done. We've replaced the SHAP values, but the data values are still one-hot encoded!"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shap_values.data[0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["unohe_data = nominal_ohe.inverse_transform(shap_values.data[:, numerical_feature_count:])\n", "unohe_data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["new_data = np.concatenate((shap_values.data[:, :numerical_feature_count], unohe_data), axis=1)\n", "new_data.shape"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shap_values.data = new_data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["#### Fixing Feature Names\n", "Lastly, we need to update the feature names since the old feature names includes the one-hot encoded features. This is straightforward:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["new_feature_names = X_test.columns[:numerical_feature_count].to_list() + list(n_ohe_feats.keys())\n", "new_feature_names"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shap_values.feature_names = new_feature_names"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### With Height and Weight\n", "Now, we can plot beeswarm plots for the model trained with the height and weight using the SHAP values.\n", "For the obese class:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shap.plots.beeswarm(shap_values[:, :, target_class_label_d[\"Yes\"]], max_display=X_test.shape[1])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For the non-obese class:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shap.plots.beeswarm(shap_values[:, :, target_class_label_d[\"No\"]], max_display=X_test.shape[1])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["### Without Height and Weight\n", "Similarly, we plot beeswarm plots for the model trained without the height and weight.\n", "For the obese class:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shap.plots.beeswarm(grouped_shap_values_no_hw[:, :, target_class_label_d[\"Yes\"]], max_display=X_test_no_hw.shape[1])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shap.plots.scatter(grouped_shap_values_no_hw[:, \"CAEC\", 0], color=grouped_shap_values_no_hw[:, :, 0])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def boxplot_categories(shap_values, feature: str, target_class: int):\n", "    values = shap_values[:, feature, target_class].values\n", "    data = shap_values[:, feature, target_class].data\n", "    categories = np.unique(data).astype(\"int\")\n", "    \n", "    groups = []\n", "    for c in categories:\n", "        relevant_values = values[data == c]\n", "        groups.append(relevant_values)\n", "    \n", "    labels = categories\n", "    \n", "    plt.figure(figsize=(8, 5))\n", "    plt.boxplot(groups, tick_labels=labels)\n", "    plt.ylabel('SHAP Values', size=15)\n", "    plt.xlabel('Obesity', size=15);"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["    # \"CAEC_Frequently\": \"CAEC\",\n", "    # \"CAEC_Sometimes\": \"CAEC\",\n", "    # \"CAEC_no\": \"CAEC\",\n", "\n", "np.unique(grouped_shap_values_no_hw[:, \"CAEC\", 0].data)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["boxplot_categories(grouped_shap_values_no_hw, \"CAEC\", 0)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["For the non-obese class:"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["shap.plots.beeswarm(grouped_shap_values_no_hw[:, :, target_class_label_d[\"No\"]], max_display=X_test_no_hw.shape[1])"]}], "metadata": {"language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 4}
