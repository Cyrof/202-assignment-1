{"cells": [{"cell_type": "markdown", "id": "2f201f51-5ade-40c6-8bf4-9b027b05eefb", "metadata": {}, "source": ["# Preprocessing"]}, {"cell_type": "markdown", "id": "335d12cd-96b4-454a-a84b-110a03ef24d5", "metadata": {}, "source": ["## Library Imports"]}, {"cell_type": "code", "execution_count": null, "id": "5bf386b0-e55b-4063-afbd-ea1a8a09da27", "metadata": {}, "outputs": [], "source": ["import os\n", "import pickle\n", "\n", "import pandas as pd\n", "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n", "from sklearn.model_selection import train_test_split"]}, {"cell_type": "markdown", "id": "50415afc-3157-4e09-b8dd-947e0ecd7760", "metadata": {}, "source": ["## Importing the Dataset"]}, {"cell_type": "code", "execution_count": null, "id": "03a7e824-7893-4890-841e-3e62029e9517", "metadata": {}, "outputs": [], "source": ["csv_path = f\"{os.path.abspath(os.path.join(os.getcwd(), os.pardir))}/datasets/obesityData.csv\"\n", "\n", "ob_df = pd.read_csv(csv_path) # ob_df --> obesity dataframe"]}, {"cell_type": "markdown", "id": "c3a312d4-80be-4626-afbe-864e4344d413", "metadata": {}, "source": ["## Splitting the Dataset\n", "The dataset is split into a training set and test set with a ratio of 70% for the training set size and 30% for the test set size. The split is stratified according to the obesity level."]}, {"cell_type": "code", "execution_count": null, "id": "423e3b5e-9dfa-4696-bd4d-5d8a1cfc8887", "metadata": {}, "outputs": [], "source": ["RAND_STATE = 0\n", "\n", "X = ob_df.drop(columns=[\"NObeyesdad\"])\n", "y = ob_df[\"NObeyesdad\"]\n", "\n", "# Split the data\n", "X_train_unencoded, X_test_unencoded, y_train_unencoded, y_test_unencoded = train_test_split(X, y, test_size=0.3, train_size=0.7, stratify=y, random_state=RAND_STATE)"]}, {"cell_type": "code", "execution_count": null, "id": "818226ed-11d9-433a-ac55-e6736c7c82a5", "metadata": {}, "outputs": [], "source": ["X_train_unencoded"]}, {"cell_type": "code", "execution_count": null, "id": "f9268f75-35a0-4d05-9e04-f93f3d593266", "metadata": {}, "outputs": [], "source": ["X_test_unencoded"]}, {"cell_type": "code", "execution_count": null, "id": "f1834968-a6e7-49db-9048-2cc97c5478f3", "metadata": {}, "outputs": [], "source": ["y_train_unencoded"]}, {"cell_type": "code", "execution_count": null, "id": "2e9775ac-8cb4-4258-b906-233d75ef3dfb", "metadata": {}, "outputs": [], "source": ["y_test_unencoded"]}, {"cell_type": "markdown", "id": "5fc323c2-3566-404c-8ef1-ae6084e1b28f", "metadata": {}, "source": ["## Feature Scaling\n", "Standardisation is used to scale the numerical features. Note that the scaler is fitted to the train set, not the test set, to prevent \"leaking\" of the test set."]}, {"cell_type": "code", "execution_count": null, "id": "e2782a71-10bb-41d4-a52a-6e25e76a8026", "metadata": {}, "outputs": [], "source": ["numerical_features = [\"Age\", \"Height\", \"Weight\", \"FCVC\", \"NCP\", \"CH2O\", \"FAF\", \"TUE\"]\n", "\n", "scaler = StandardScaler().fit(X_train_unencoded[numerical_features])\n", "\n", "X_train = X_train_unencoded.copy()\n", "X_train[numerical_features] = scaler.transform(X_train_unencoded[numerical_features])\n", "X_train"]}, {"cell_type": "code", "execution_count": null, "id": "612d5171-03c3-4514-bba5-34f039850ef2", "metadata": {}, "outputs": [], "source": ["X_test = X_test_unencoded.copy()\n", "X_test[numerical_features] = scaler.transform(X_test_unencoded[numerical_features])\n", "X_test"]}, {"cell_type": "markdown", "id": "41531b10-a447-44f0-b6a6-e0ffcfd47737", "metadata": {}, "source": ["## Categorical Feature Encoding\n", "The categorical features need to be encoded. We will use label encoding and one-hot encoding."]}, {"cell_type": "markdown", "id": "b4187423-a69e-46c3-a329-cb5ff18cf639", "metadata": {}, "source": ["### Target Feature\n", "The target feature (obesity level) is encoded using label encoding."]}, {"cell_type": "code", "execution_count": null, "id": "07699ae5-4637-46d9-92ce-e5991a00df53", "metadata": {}, "outputs": [], "source": ["target_le = LabelEncoder()\n", "target_le.fit(ob_df[\"NObeyesdad\"]);"]}, {"cell_type": "code", "execution_count": null, "id": "597243e2-8d0d-4a70-aadc-063fa54d54c5", "metadata": {}, "outputs": [], "source": ["def le_encode(y_unencoded):\n", "    y = y_unencoded.copy()\n", "    y.loc[:] = target_le.transform(y_unencoded)\n", "    return y.astype(\"int\")"]}, {"cell_type": "code", "execution_count": null, "id": "46a5f61f-91cc-428d-956b-e08955e7a148", "metadata": {}, "outputs": [], "source": ["y_train = le_encode(y_train_unencoded)\n", "y_train"]}, {"cell_type": "code", "execution_count": null, "id": "6e11f195-e3af-42a7-b40a-7681993a87e0", "metadata": {}, "outputs": [], "source": ["y_test = le_encode(y_test_unencoded)\n", "y_test"]}, {"cell_type": "markdown", "id": "4797f44a-06ef-46ec-84d8-1f434d8c988f", "metadata": {}, "source": ["### Non-Target Features\n", "We now encode the other categorical features. In this case, they all happen to be nominal, hence one-hot encoding is used.\n", "The first column for each feature after encoding is dropped.\n", "First, we create the one-hot encoder:"]}, {"cell_type": "code", "execution_count": null, "id": "2286adf5-6de0-493e-86cc-41f4dbd32d9d", "metadata": {}, "outputs": [], "source": ["nominal_features = [\n", "    \"Gender\",\n", "    \"family_history_with_overweight\",\n", "    \"FAVC\",\n", "    \"CAEC\",\n", "    \"SMOKE\",\n", "    \"SCC\",\n", "    \"CALC\",\n", "    \"MTRANS\"\n", "]\n", "\n", "nominal_ohe = OneHotEncoder(drop=\"first\", sparse_output=False)\n", "nominal_ohe.fit(ob_df[nominal_features]);"]}, {"cell_type": "markdown", "id": "1e392b92-6977-4e74-aa1b-a7d25f3e297b", "metadata": {}, "source": ["Next, we transform the categorical features' values in `X_train` and `X_test` using the encoder.\n", "The original `X_train` and `X_test` dataframes are then modified to use the columns from the one-hot encoding. The old non-encoded features are dropped."]}, {"cell_type": "code", "execution_count": null, "id": "9d126da1-6c34-4e56-8619-90bfa21de7a7", "metadata": {}, "outputs": [], "source": ["def ohe_transform(X):\n", "    ohe_train_transformed = nominal_ohe.transform(X[nominal_features])\n", "\n", "    # Convert back into a dataframe.\n", "    pd_train_transformed = pd.DataFrame(ohe_train_transformed, columns=nominal_ohe.get_feature_names_out(), index=X.index)\n", "    \n", "    return pd.concat([X.drop(nominal_features, axis=1), pd_train_transformed], axis=1)"]}, {"cell_type": "code", "execution_count": null, "id": "da032647-4fa9-4cff-88d2-2677098d74fc", "metadata": {}, "outputs": [], "source": ["X_train = ohe_transform(X_train)\n", "X_train"]}, {"cell_type": "code", "execution_count": null, "id": "12e48cc0-c5ed-4e26-8ebe-783b5e46ff6b", "metadata": {}, "outputs": [], "source": ["X_test = ohe_transform(X_test)\n", "X_test"]}, {"cell_type": "markdown", "id": "5170d3ed-fe05-4a9e-8bea-6ae1ed506386", "metadata": {}, "source": ["## Export\n", "Now, we export the preprocessed data to CSV files."]}, {"cell_type": "code", "execution_count": null, "id": "e7900e46-52db-48aa-a3d8-7ca7291daa99", "metadata": {}, "outputs": [], "source": ["datasets_folder = f\"{os.path.abspath(os.path.join(os.getcwd(), os.pardir))}/datasets\"\n", "def save_df(df, filename):\n", "    path = os.path.join(datasets_folder, filename)\n", "    df.to_csv(path)\n", "    print(f\"Dataframe saved to \\\"{path}\\\"\")"]}, {"cell_type": "code", "execution_count": null, "id": "fc085055-9452-4624-b11d-6851efed6089", "metadata": {}, "outputs": [], "source": ["save_df(X_train, \"obesity_X_train.csv\")\n", "save_df(X_test, \"obesity_X_test.csv\")\n", "save_df(y_train, \"obesity_y_train.csv\")\n", "save_df(y_test, \"obesity_y_test.csv\")"]}, {"cell_type": "markdown", "id": "e68581d1-8781-420d-9126-c110f0920209", "metadata": {}, "source": ["The non-preprocessed data after splitting are also saved:"]}, {"cell_type": "code", "execution_count": null, "id": "ded30b84-3e4e-4111-b47e-40d353b63bd9", "metadata": {}, "outputs": [], "source": ["save_df(X_train_unencoded, \"obesity_X_train_unencoded.csv\")\n", "save_df(X_test_unencoded, \"obesity_X_test_unencoded.csv\")\n", "save_df(y_train_unencoded, \"obesity_y_train_unencoded.csv\")\n", "save_df(y_test_unencoded, \"obesity_y_test_unencoded.csv\")"]}, {"cell_type": "markdown", "id": "40637788-8e71-4ba3-a652-2befa791c8be", "metadata": {}, "source": ["We also need to export the encoders so that they can be used in other notebooks. This is done through pickling:"]}, {"cell_type": "code", "execution_count": null, "id": "480fe954-4dc5-4bec-8763-03d95052da86", "metadata": {}, "outputs": [], "source": ["def save_encoder(encoder, filename):\n", "    file_path = f\"{os.path.abspath(os.path.join(os.getcwd(), os.pardir))}/encoders/{filename}\"\n", "    with open(file_path, 'wb') as file: \n", "        pickle.dump(encoder, file)\n", "    file.close()\n", "    print(f\"Encoder saved to {file_path}\")"]}, {"cell_type": "code", "execution_count": null, "id": "5732df5d-4cf9-4b59-b61c-6cc2bbaa368a", "metadata": {}, "outputs": [], "source": ["save_encoder(scaler, \"scaler.pkl\")"]}, {"cell_type": "code", "execution_count": null, "id": "54a1baaf-1fd7-421b-ab24-1bd53d595d5f", "metadata": {}, "outputs": [], "source": ["save_encoder(target_le, \"target_le.pkl\")"]}, {"cell_type": "code", "execution_count": null, "id": "b24e79b0-5e3a-4851-aa7c-e981e5398b08", "metadata": {}, "outputs": [], "source": ["save_encoder(nominal_ohe, \"nominal_ohe.pkl\")"]}], "metadata": {"language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}
