{"cells": [{"cell_type": "markdown", "id": "2f201f51-5ade-40c6-8bf4-9b027b05eefb", "metadata": {}, "source": ["# Model Selection\n", "Nested cross-validation with stratified 10-fold cross-validation and grid search is used for model selection."]}, {"cell_type": "markdown", "id": "335d12cd-96b4-454a-a84b-110a03ef24d5", "metadata": {}, "source": ["## Library Imports"]}, {"cell_type": "code", "execution_count": null, "id": "af10a09f-02ec-41a2-a672-f6839fd7a908", "metadata": {}, "outputs": [], "source": ["import os\n", "\n", "import pandas as pd\n", "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n", "from sklearn.linear_model import LogisticRegression\n", "from sklearn.ensemble import RandomForestClassifier\n", "from sklearn.tree import DecisionTreeClassifier\n", "from sklearn.svm import SVC\n", "\n", "RAND_STATE = 0"]}, {"cell_type": "markdown", "id": "50415afc-3157-4e09-b8dd-947e0ecd7760", "metadata": {}, "source": ["## Importing the Train Set"]}, {"cell_type": "code", "execution_count": null, "id": "564f567d-0ca4-45f5-ad72-d71774fddc79", "metadata": {}, "outputs": [], "source": ["datasets_folder = f\"{os.path.abspath(os.path.join(os.getcwd(), os.pardir))}/datasets\""]}, {"cell_type": "code", "execution_count": null, "id": "32152cda-ab54-43f7-8291-433aad68f4c2", "metadata": {}, "outputs": [], "source": ["X_train = pd.read_csv(os.path.join(datasets_folder, \"obesity_X_train.csv\"), index_col=0)\n", "X_train"]}, {"cell_type": "code", "execution_count": null, "id": "ba987709-c1b1-4c8a-8c14-f122116a874c", "metadata": {}, "outputs": [], "source": ["y_train = pd.read_csv(os.path.join(datasets_folder, \"obesity_y_train.csv\"), index_col=0)[\"Obese\"]\n", "y_train"]}, {"cell_type": "markdown", "id": "c6827e4c-2955-4320-9fe0-d114f1a7dbb7", "metadata": {}, "source": ["### Dropping the `Weight` Column\n", "The obesity level is highly correlated with the weight. This makes it fairly easy for models to achieve high accuracy, but makes explanations uninsightful because everyone knows obesity depends on weight. Hence, we make a variant of `X_train` that does not have the `Weight` column:"]}, {"cell_type": "code", "execution_count": null, "id": "53860e3a-0d38-4a04-a6f7-c3113a8316b3", "metadata": {}, "outputs": [], "source": ["X_train_no_weight = X_train.drop(\"Weight\", axis=1)\n", "X_train_no_weight"]}, {"cell_type": "markdown", "id": "d37289d4-9b9e-48cd-b7f7-e843361a7580", "metadata": {}, "source": ["We will cross-validate for `X_train` and `X_train_no_weight` separately."]}, {"cell_type": "markdown", "id": "1d5295d0-e55f-4839-92cd-6894eb99d48c", "metadata": {}, "source": ["## Models\n", "\n", "Logistic regression, random forests, decision trees and support vector machines are selected for comparison."]}, {"cell_type": "code", "execution_count": null, "id": "9c0e0eff-ba2e-4dd0-8ac6-1a1a4292857d", "metadata": {}, "outputs": [], "source": ["models = {\n", "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=RAND_STATE),\n", "    'Random Forest': RandomForestClassifier(random_state=RAND_STATE),\n", "    'Decision Tree': DecisionTreeClassifier(random_state=RAND_STATE),\n", "    'SVM': SVC(probability=True, random_state=RAND_STATE)\n", "}"]}, {"cell_type": "markdown", "id": "eea98620-87b6-4bd9-9106-8ec5d2383fba", "metadata": {}, "source": ["## Hyperparameter Grids\n", "\n", "We will be using a grid search, so we define the hyperparameter grids for tuning each model."]}, {"cell_type": "code", "execution_count": null, "id": "cb30d3de-87c5-48f5-96e9-d69f416bbce2", "metadata": {}, "outputs": [], "source": ["param_grids = {\n", "    'Logistic Regression': {'C': [0.001, 0.01, 0.1, 1, 10, 100]},\n", "    'Random Forest': {'n_estimators': [50, 100, 200, 300, 400], 'max_depth': [None, 5, 10, 20, 30]},\n", "    'Decision Tree': {'max_depth': [None, 5, 10, 20, 30], 'min_samples_split': [2, 5, 10, 20]},\n", "    'SVM': {'C': [0.01, 0.1, 1, 10, 100], 'kernel': ['linear', 'rbf', 'poly']}\n", "}"]}, {"cell_type": "markdown", "id": "6f6f6efa-e734-407b-bcb9-eb49494f39d9", "metadata": {}, "source": ["## Performing Nested Cross-Validation\n", "\n", "We perform nested cross-validation using 10 folds (stratified) and a grid search for hyperparameter tuning."]}, {"cell_type": "code", "execution_count": null, "id": "eefca550-5e78-4104-bb4f-3e94b812d543", "metadata": {}, "outputs": [], "source": ["# Performs nested cross-validation for a model.\n", "def cross_validate(model_name, model, X):\n", "    # Use stratified k-fold with k = 10.\n", "    inner_cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=RAND_STATE)\n", "    \n", "    # Perform hyperparameter tuning using a grid search.\n", "    search_cv = GridSearchCV(\n", "        model,\n", "        param_grids[model_name],\n", "        cv=inner_cv,\n", "        scoring='accuracy',\n", "        n_jobs=-3 # Use 2 less than the number of CPUs\n", "    )\n", "    search_cv.fit(X, y_train)\n", "    \n", "    return model_name, search_cv\n", "\n", "for X_name, X in {\"X_train\": X_train, \"X_train_no_weight\": X_train_no_weight}.items():\n", "    print(f\"Dataframe: {X_name}\\n\")\n", "    for model_name, search_cv in (cross_validate(model_name, model, X) for model_name, model in models.items()):\n", "        print(f\"Model: {model_name}\")\n", "        print(f\"Best Score: {search_cv.best_score_:.3f}\")\n", "        print(f\"Best Parameters: {search_cv.best_params_}\\n\\n\")"]}, {"cell_type": "markdown", "id": "ef68e0cf-0df1-4657-a432-405037fd0b58", "metadata": {}, "source": ["All models, except logistic regression, with their best parameters achieved high accuracy on both sets."]}], "metadata": {"language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 5}
